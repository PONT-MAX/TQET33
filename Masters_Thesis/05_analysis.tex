\section{Discussion} %Resultat ska inte analyseras, diskuteras eller värderas. Detta lämnas till diskussionskapitlet. 
\label{sec:discussion}
In this section the results and method is analyzed and discussed. When discussing results a focus on consistency, relation to theory and real world applicability is held. In the discussion of method an analysis of replicability, reliability and  validity is held.

\subsection{Result} 
%Finns det något i resultaten som står ut och behöver analyseras och kommenteras? Hur förhåller sig resultaten till det material som togs upp i teorigenomgången? Vad säger teorin om vad resultaten egentligen betyder? Vad innebär det till exempel att man vid en användbarhetsmätning av ett nytt system fått ett visst värde; hur bra eller dåligt är det? Finns det något i resultaten som är oväntat baserat på teorigenomgången, eller stämmer det bra överens med vad man teoretiskt kunde förvänta sig? 
Overall the results obtained in this thesis reflects what has been stated in the theory and research, but no reference to the use of SPC in natural environment could be found and thus this thesis will present the link between real world application and theory/lab results and the challenges that come with it. 



\subsubsection{Reconstruction performance Using reference image}
\label{sec:anlys_ref_im}
%Sec:reconstruction performance using ref im
%A second observation is that, when the noise increases the  reconstructed image quality is not improved at the same rate as the noiseless case when increasing the sub sampling ratio.
In the simulated reconstruction the results behaved in most part as expected given the CS theory, with increased subsampling ratio the performance increased. But the interesting part of this results is whats happening when increasing the noise, not only does the general performance drop for all subsample ratios, but also the improvement rate by increasing the subsample ratio drops, which figure~\ref{fig:snr} and \ref{fig:ssim_3d} shows. This result tells us that if the signal contains a high degree of noise, a larger subsampling ratio may not improve the reconstructed image as mush as expected.\\[0.1in]

When obtaining the same measurements with the SPC one low frequency image was captured and reconstructed, with near optimal SNR and environment such that a homography between the reconstructed image and reference image could be made with good precision. In figure~\ref{fig:hom_psnr} and \ref{fig:hom_ssim} we can see the PSNR and SSIM of the image given the reference image, as expected from theory and confirmed in the simulated case the performance increases when the subsampling ratio increases. But if we look closer at the PSNR plot we can see that the largest increase in performance is up to 15\% subsampling ratio, which can be confirmed when inspecting the images in figure~\ref{fig:hom_5}-\ref{fig:hom_30}, where the image quality rapidly improves when increasing subsample ratio up to 15\%, then the improvement rate stagnates.


\subsubsection{Reconstruction performance Using no reference quality assessment}
For the simulated reconstruction in figure~\ref{fig:Brisque_3d}, we can see that the graph looks like a upside down version of the PSNR and SSIM graphs of the simulated images. This results alone is positive for this theses because it was unknown if this method would work well for SWIR images and reconstructed images. An observation that can be made, is that the reference images score about 20 BRISQUE points better then the best reconstructed images and we can conclude that the sampling and reconstruction even in the best case scenario without noise, will not be as good as an conventional camera. We can see from the plot that in the ideal case the score will not be better then approximately 40 BRISQUE points for the reconstructed images while the SWIR images has a mean value of 15. We can concluded from this result that, with the current measurement matrix and reconstruction method, around 40 in BRISQUE score is what to expect as optimum given that the SPC will induce some noise to the signal.\\[0.1in]
%When studying the more sparse 2D plot in figure~\ref{fig:Brisque_2d}, the observations from section~\ref{sec:anlys_ref_im} is confirmed that the improvement in image quality  


When studying the plot with BRISQUE score given by the results from images reconstructed from the SPC in figure~\ref{fig:brisque_plot}, we can see that the best images score just over 40 BRISQUE points, which is the same score as score as simulated images with small or no nois added, which means that the SPC can compare to the benchmark set by the simulation and thus gives a theoretical optimal reconstuction given the measurement matrix and reconstruction algorithm. Furthermore we can see that the trend of the images follows the same characteristics as the simulation in figure~\ref{fig:Brisque_2d} for different noise levels, thus we can conclude that simulations gives a good indication of where the real images will score given a noise level.\\[0.1in]

In figure~\ref{fig:good} to \ref{fig:bad}, we see the images divided into three classes given their BRISQUE score and trend as described in section~\ref{sec:SPC_BRISQUE}. As the BRISQUE score tells, the quality of the images should vary a lot, and when taking a closer look the "bad" data set in figure~\ref{fig:bad} stands out the most. My analysis of why the BRISQUE score and image quality differ is, 

\begin{itemize}
\item first if we take a look at the images in figure~\ref{fig:good} and \ref{fig:half}, where the image quality and lighting look quiet the same but yet differ so much in the BRISQUE score, it might be a property of the BRISQUE classifer. The BRISQUE classifier is built to assess image quality in natural images, and if we take a look at the main difference between these two data sets we can see that one is pictures of a car, humans, forest and clothing and the other mainly of buildings and large structure in the images with little change i.e. not so natural, which can effect the score.

\item The major difference between figure~\ref{fig:good} - \ref{fig:half} and \ref{fig:bad} is that the latter appears to contain a lot more global noise. The increase in global noise arises from two separate sources, the fist one being luminance in the scene, we can see that the images in figure~\ref{fig:half1} and \ref{fig:bad1} is practically the same motive, but the latter is darker. The darker scene was shot in morning when the sun was not so bright and did not luminate the facade directly and thus the signal was weaker and the resulting reconstruction was effected more by the sensors background noise and gave rise to global noise in the produced image. 

\item The second reason is large structure movement in the scene, most of the images in the "bad" image set had movement mainly from clouds when sampled which definitely increased global noise in the reconstructed images as concluded in section~\ref{sec:Dynamics_in_scene} and therefore decreased the BRISQUE score significantly.

\end{itemize}

In the last part of section~\ref{sec:SPC_BRISQUE} the results from plotting SNR and standard deviation against mean signal intensity in figure~\ref{fig:snr}, was presented. Each data point had also been color coded to match the classification made previously, the plots gave more information on why the BRISQUE score was so deviated. From the plot in figure~\ref{fig:snr_v_sigma} it becomes very clear at which mean signal intensity we can expect to produce good images given that the background noise becomes insignificant. But in the plots there are only two signals with higher variance than 0.04, which is the threshold where the the simulated images started to get both worse initial BRISQUE score and worse trend when increasing the subsampling ratio in figure~\ref{fig:Brisque_2d}. This implies that there probably must be at least one additional factor at play to reduce the image quality in the "bad" set.\\[0.1in]


We can see that there are a subset of red images with almost the same SNR and mean signal intensity as yellow and green images but yields a worse BRISQUE score anyway, this strengthening the statement the there is probably at least on more factor that reduces reconstruction performance. And as stated in the last paragraph this is probably due to motion in the scene when sampling the signal. Unfortunately for this experiment, it seams like the images containing motion also had a low mean signal intensity, otherwise we would probably also have "bad" images for stronger mean signals.\\[0.1in] 

The last observation in these plots are the mix of "good" and "half good" images in the whole mean intensity span, which tells that a strong signal will not yield a good BRISUQE score, which implies that the motive in the images effecting the BRISQUE score as suspected in when inspecting the reconstructed image sets.

\subsubsection{Dynamics in scene}
In this category there are results both from the simulated images and from the SPC, where the results was divided into three characteristic dynamics: small local changes in the scene, large global changes and luminance change.\\[0.1in]

The effect on the signal of local movements result shown in figure~\ref{fig:local_dyn}, we can see that there is no significant difference between the non perturbed reference signal and the distorted signal. It can even be interpreted as added noise to the signal and it is barely detectable even if the signal is known. The effect on the reconstructed image, seen in figure~\ref{fig:local_1}, looks like global noise is added. The conclusion of that test implies that local movement in a scene will distort the reconstructed image globally and especially locally where the movement occurred. It also tells that local movement is very hard to detect in the signal even if a reference signal is available.\\[0.1in]

When increasing the movement and modeled an unseen object pass through, the samples with movement was very easy to spot, which figure~\ref{fig:local_sig_2} shows. The effect in the reconstructed image is as expected even worse then local movement, with a global distortion, seen in figure~\ref{fig:local_2}. In this simple isolated case the image could be saved by removing the measurements when the object was moving, reconstructing an image with fewer measurements. The resulting image would not be as good as the image in figure~\ref{fig:fly_2} but it would not contain the noise present in figure~\ref{fig:fly_3}. \\[0.1in]


%Comment luminance change case ?
In the case of luminance change, the effect on the reconstructed image is even worse than scenes containing movement, which figure~\ref{fig:local_3} and comparing table~\ref{tab:local_dyn}, \ref{tab:fly_dyn} and \ref{tab:lum_dyn}. Because we know that this problem is real and can not be avoided in natural scenes, a model to suppress this issue was tested with good result, but as can be seen in figure~\ref{fig:lum_sig_3}, \ref{fig:lum_dyn} and table~\ref{tab:lum_dyn}, the method will not suppress the effect completely even on a simulation and thus add some global noise in the same form as local movement will.\\[0.1in]

% SPC
When capturing images using the SPC, the luminance change became a larger problem than anticipated. All image captured in natural lighting had luminance change and it changed at a higher frequency and larger amplitude even in scenes where the intensity seemed stationary. This is of course due to the fact that the intensity change from every mirror in the DMD is summed in the sensor, so even for small changes the sum will change the signal significantly, as seen in figure~\ref{fig:lc_plot}. But as seen in the results in figure~\ref{fig:lc_image}, the moving average method worked despite the more complex changes to the signal. Considering that this problem was consistent for all natural images this method became essential for this thesis to produce any good result at all. As stated before, this method is an model of global luminance change in the image, and therefore it is hard to know which side effects this method have on image quality. But as the test show, the method is essential and was used for all images captured by the SPC and presented and evaluated in this thesis.\\[0.1in]

This method was mainly constructed because I knew the SPC would have a long exposure time, but even if the exposure time is reduced to a a few seconds or less, there is some indication that the luminance change will still effect the result. In this thesis, the moving average window corresponded to 50 milliseconds which indicates that the luminance change is so fast that even reducing exposure time could benefit to this method.\\[0.1in]


Basically all scenes i natural environment contained both dynamics from local movement and luminance change, local movement often arose from vegetation, objects or clouds moving in the wind but also from turbulence which not move the object but how it is perceived on the DMD. Because of all the dynamics presented that is persistent even in a "static" scene, I decided to not photograph scenes where large movement occurred as a car, object or human, even though it could be detected, because it could also be detected as luminance change.\\[0.1in]

As stated, even "static" scenes will with high probability contain both movement and luminance change which will effect the reconstructed images. Therefor I can conclude that all reconstructed images in this thesis has to some degree added global noise from local movement and the signal processing to counter luminnnce change.


\subsubsection{Edge response}
When comparing the edge response between the conventional camera against the SPC the results was very clear, the conventional camera outperformed the SPC with one to two pixels in distance. I think there are multiple factors why the results from the SPC differed so much from the conventional camera, and have listed them below,

\begin{itemize}
\item The largest impact on image quality is probably the reconstruction algorithm which produces "patches", which can be seen in the SPC images in figure~\ref{fig:mtf_target_im}, especially in the contrast of the white background where the light intensity drops. The "patch" artifact from the reconstruction algorithm can effect the sharpness of the image. We can also see from previous test that even from synthetic data the BRISQUE score is significantly worse then the original image.

\item The pixel grid setup in the DMD has two problems that could effect the sharpness. In the DMD the mirrors is aligned in a diamond shape of pattern and in the current setup to fix the ratio and index two mirrors is merged to form one pixel. The reconstruction algorithm will still interpret the measurement as a regular square pixel which can distort the image.

\item The focus in the DMD is set manually.

\item In this thesis no significant image improvement from post processing such as denoise or sharpening was performed unlike the conventional camera.

\item And as stated before, with the long exposure, vibrations and light intensity change effected the results (the SPC could detect significant light intensity change from the halogen lamp powered by a DC-unit), which contribute to global noise in the reconstruction.

\end{itemize}



\subsubsection{Subsampling ratio}
The first results from section~\ref{sec:measurements} was the minimum subsampling ratio required to reconstruct a merely recognizable image, for the whole image set the results varied between 2-4\%. The variance could be effected by several factors such as image complexity, SNR and dynamics in the scene, which contribute to add uncertainty to the equation system. With the knowledge of minimum subsampling ratio a fast exposure and thus a fast reconstruction could be applied to form a test image, which could be used to calibrate and make decision how to sample the long exposure real image.\\[0.1in]

In the second part of section~\ref{sec:measurements}, a set of images reconstructed with different subsampling ratio was presented. The result is presented for the reader to obtain a more concrete perception of the generated image quality and a supplement to the numerical results given subsampling ratio, but also overall expected image quality.

\subsection{Method} %Vad jag tycker om det (personliga tankar)
%In the discussion of method an analysis of replicability, reliability and  validity is held.

The methods used in thesis can be divided into four categories, the SPC hardware, the sampling matrix and reconstruction, post processing and the method used to capture the images. Two of these categories, the hardware setup and the sampling matrix and reconstruction was heavily influenced and implemented by widely accepted methods from articles and experiments. While the two other categories, the post process and the image capturing dependent more on the hardware limitation and competence achieved from the university.\\[0.1in]

The first method in the chain was feeding the DMD measurement matrices and sampling the signal. Because of the interface to the DMD, which acted as a second monitor to the computer, the method to stream the measurement matrices as a video was thought to be a good method because it was easy to implement. In the early stages of this thesis a much smaller resolution of $128 \times 128$ pixels was thought to be a feasible maximum and thus much less measurement matrices needed to be streamed to the DMD while having the same exposure time. With that initial goal in mind the video player steaming method would have worked well. But when the target resolution was pushed the video players frame rate had to be pushed to its limits in an application it was not designed to handle. This resulted in a higher probability that the video player would go out of sync and thus ruin the reconstruction and there was no way of knowing if this had happen. By the time this issue was discovered there where no time of changing and implement a new method but was much needed.\\[0.1in]

The sampling matrix chosen in this thesis was the sequency ordered Walsh Hadamard measurement matrix, this sampling matrix in unison with implemented fast transform in the reconstruction algorithm enabled the huge increase in image resolution. This method of using structurally random matrices is the only feasible method today to enable high resolution and fast reconstruction with low memory usage in the computer thus if implemented optimally both the feeding of measurement matrices to the DMD and reconstruction could be calculated in run time in a memory efficient program.\\[0.1in]

The reconstruction algorithm TVAL3 was used throughout this masters thesis and was chosen after the literature study where several articles mentioned total variation as a good optimization algorithm for compressive imaging. The algorithm worked as described and according to the developer and is one of the fastest and best reconstruction algorithms that are free to use and available. The only negative criticism of using this algorithm is that it seems to produce a dark tint in the edges of the reconstructed images.\\[0.1in]

In the post process quite basic signal and image processing was performed and was intentional designed that way in order to present the result as true as possible. One algorithm was developed specific for the SPC which was the average mean algorithm to suppress the impact of lumination change in the sampled signal. The algorithm showed great result and became essential when taking photos of scenes outdoor. Both hardware and software signal denoising was implemented to the architecture but had to be changed every time the DMD update rate was changed, which happened a couple of times. Finding a new solution every time was a time consuming task and dropped completely in the end when good results was achieved anyway. If I had more time or a target DMD rate would have been set earlier a good signal denoising implementation could have improve the result.\\[0.1in]

\subsubsection{Replicability, reliability \& validity}
Given the description of method in this thesis I think it would be quiet straight forward to replicate this experimental setup and architecture. The setup is quiet simple and the software developed is not so heavy, therefor I think this experiment have good replicability.\\[0.1in]

In the case of compressive imaging the reliability and validity goes hand in hand, if whats being measured is not the correct data the reconstruction will fail and if the reconstruction succeed the measurement must be correct. Therefore copressive sensing is very binary, ether you get it right or you fail and thus I think my result have both high validity and reliability.  

 
% Reliabilitet är ett begrepp som beskriver mätningens kvalitet: hur väl kan man lita på data som insamlats och hur det används för att dra slutsatser. Om reliabiliteten är hög, så bör samma/liknande resultat kunna uppnås om man gör om studien med samma metod.

%Validitet handlar lite förenklat om huruvida man i en mätning mätt det man tror sig mäta. En studie med hög validitet har alltså en hög grad av trovärdighet.



%\subsection{Work in a Broader context}
%Det ska ingå ett stycke med en diskussion om etiska och samhälleliga aspekter relaterade till arbetet. Detta är viktigt för att påvisa professionell mognad samt för att utbildningsmålen ska kunna uppnås. Om arbetet av någon anledning helt saknar koppling till etiska eller samhälleliga aspekter ska detta explicit anges i stycket Avgränsningar i inledningskapitlet. 

% Jag tror detta är fallet då det är en ny sorts kamera, det finns väl inget morariskt fel att bygga en kamera som är effektivare? och den borde inte få några samhelliga effekter?
