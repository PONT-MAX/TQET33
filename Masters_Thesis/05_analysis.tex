\chapter{Discussion} %Resultat ska inte analyseras, diskuteras eller värderas. Detta lämnas till diskussionskapitlet. 
\label{sec:discussion}
In this section the results and the method are analyzed and discussed. When discussing results, a focus on consistency, relation to theory and real world applicability is held. In the discussion of method, an analysis of replicability, reliability and  validity is held as well as the method used to capture images with the SPC.

\section{Results} 
Overall, the results obtained in this thesis reflect what has been stated in theory and research before. However no reference of using the SPC to capture natural scene has been found and thus this thesis will present the link between real world applications and theory/lab results and the challenges that come with it. 



\subsection{Reconstruction performance using reference image}
\label{sec:anlys_ref_im}

In the simulated reconstruction, the results behaved in most parts as expected given the CS theory i.e. with increased subsampling ratio, the performance increased. However the interesting part of the results is what happens when increasing the noise. Not only does the general performance drop for all subsample ratios, but also the improvement rate by increasing the subsample ratio drops, which figure~\ref{fig:psnr_3d} and \ref{fig:ssim_3d} shows. This result tells us that if the signal contains a high degree of noise, a higher subsampling ratio may not improve the reconstructed image as much as expected. However, the result could be questioned in images with a lot of noise, where both PSNR ans SSIM shows worse results with higher subsampling ratio, but the images subjectively looks better as seen in figure~\ref{fig:noisy}.\\[0.1in]

When performing similar measurements with the SPC, one low frequency image was captured and reconstructed. The images were captured in a near optimal environment, so that a homography could be established between the reconstructed image and the reference image with good precision. In figure~\ref{fig:hom_psnr}, we can see that the PSNR and SSIM of the SPC images compared to reference images act as theory predicted and confirmed in simulations. The performance increases non linearly when the subsampling ratio increases. If we look closer at the PSNR plot, we can see that the largest increase in performance is up to 15\% subsampling ratio, which can be confirmed when inspecting the images in figure~\ref{fig:hom_over_im}, where the image quality rapidly improves when increasing subsample ratio up to 15\%, then the improvement rate stagnates.


\subsection{Reconstruction performance using no reference quality assessment}
The graph of the simulated reconstruction results in figure~\ref{fig:Brisque_3d} looks like an inverted version of the PSNR and SSIM graphs in figure~\ref{fig:psnr_3d} and \ref{fig:ssim_3d}. This results alone are positive for this thesis, because it was unknown if the BRISQUE evaluation method would work well for SWIR images and  reconstructed images from the SPC. However, the result is not perfect for images with a lot of noise, where the BRISQUE score gets worse with higher subsampling ratio while the corresponding images subjectively looks better as seen in figure~\ref{fig:noisy}. We can also see that the reference images score about 20 BRISQUE points better than the best reconstructed images. Consequently even in the best case scenario without noise and a high subsampling ratio, the SPC will not yield as good results as a conventional camera. This evaluation was performed with the specific motivation to evaluate the measurement matrix and reconstruction method, and these results shows that an SPC will not be able to reconstruct images with the same quality as a conventional SWIR camera. Besides these results give a hint of which BRISQUE score can be expected from the SPC in the optimal case. Consequently a BRISQUE score equal to 40 can be seen as the optimum given that noise and post processing have affected the sampled signal.\\[0.1in]
%When studying the more sparse 2D plot in figure~\ref{fig:Brisque_2d}, the observations from section~\ref{sec:anlys_ref_im} is confirmed that the improvement in image quality  


When studying BRISQUE scores from natural images reconstructed by the SPC in figure~\ref{fig:brisque_plot}, we can see that the best images score just over 40 BRISQUE points, which is in agreement with the results for simulated images with small or no noise added. This means that the SPC can compare to the benchmark set by the simulation and thus gives a theoretical optimal reconstuction given the measurement matrix and reconstruction algorithm. Furthermore we can see that the trend of the images follows the same characteristics as the simulation in figure~\ref{fig:Brisque_2d} for different noise levels. Thus we can conclude that simulations give a good indication of where the real images will score, given a certain noise level.\\[0.1in]

In figure~\ref{fig:good} to \ref{fig:bad}, we see sample images from three classes given their BRISQUE score and trend as described in section~\ref{sec:SPC_BRISQUE}. As the BRISQUE score tells, the quality of the images should vary a lot, and when taking a closer look the red image set in figure~\ref{fig:bad} it stands out the most. My analysis of why the BRISQUE score and image quality differ is summarized in the following three points. 

\begin{itemize}
\item The images from the green and yellow sets in figure~\ref{fig:good} and \ref{fig:half}, have a similar image quality and lighting, but yet they differ in the BRISQUE score. This might be a property of the BRISQUE classifer, which is built to assess image quality in natural images. If we take a look at the main difference between these two data sets, we can see that one contains pictures of a car, humans, forest and clothing and the other mainly of buildings and large structures with smooth surfaces and low frequencies. These are not so "natural", which can affect the score.

\item The major difference between the images in the gren and yellow image set compared to the red image set is that the latter appears to contain a lot more global noise. The increase in global noise arises from two separate sources, the first one being the light intensity, we can see that the images in figure~\ref{fig:half2} and \ref{fig:bad1} are practically the same motive, but the latter is darker and noisier. The darker scene was shot in morning when the sun did not illuminate the facade directly. Thus the sampled signal was weaker and the resulting reconstruction was effected more by the sensors background noise and gave rise to global noise in the produced image. 

\item The second reason for worse BRISQUE score in the red set is large movement in the scene. Most of the images in the red set had movement mainly from clouds when sampled, which definitely increased global noise in the reconstructed images as seen in the results in section~\ref{sec:Dynamics_in_scene}.

\end{itemize}

In the last part of section~\ref{sec:SPC_BRISQUE}, the results from plotting normalized noise standard deviation against mean signal intensity in figure~\ref{fig:snr_v_sigma}, was presented. The plot give more information on why the BRISQUE score differed between the sets. From the plot it becomes clear at which mean signal intensity we can expect to produce good images given that the background noise becomes insignificant. But in the plots there are only two signals with higher standard deviation than 0.04, which is the threshold where the the simulated images started to get both worse initial BRISQUE score and worse trend when increasing the subsampling ratio in figure~\ref{fig:Brisque_2d}. This implies that there probably must be at least one additional factor at play to reduce the image quality in the red image set.\\[0.1in]


In figure~\ref{fig:snr_v_sigma}, we can see that there are a subset of images from the red image set with almost the same normalized noise standard deviation and mean signal intensity as from the yellow and green image sets but yields a worse BRISQUE score anyway. This strengthens the statement the there probably is at least one more factor that reduces reconstruction performance. Furthermore as stated in the third point above, this is probably due to motion in the scene when sampling the signal. Unfortunately for this experiment, it seams like the images containing motion also had a low mean signal intensity, otherwise we would probably also have "bad" images for stronger mean signals.\\[0.1in] 

The last observation in these plots is the mix of images from the green and yellow image set in the whole mean intensity span, which tells that a strong signal will not yield a good BRISUQE score, which implies that the motive in the images affecting the BRISQUE score as suspected when inspecting the reconstructed image sets.

\subsection{Dynamics in scene}
In this category there are results both from the simulated images and from the SPC, where the results was divided into three characteristic dynamics: small local changes in the scene, large global changes and luminance change.\\[0.1in]

The effect of local movements on the sampled signal is shown in figure~\ref{fig:local_dyn}. We can see that there is no significant difference between the unperturbed reference signal and the distorted signal. The effect on the reconstructed image, seen in figure~\ref{fig:local_3}, looks like global noise is added and where the object is moving the image gets extra blurry. The test implies that local movement in a scene will slightly distort the reconstructed image globally and especially locally where the movement occurred. It also tells that local movement is very hard to detect in the signal even if a reference signal is available.\\[0.1in]

When increasing the movement by letting an object passing through the whole scene, the samples with movement was very easy to spot, which figure~\ref{fig:fly_sig} shows. The effect in the reconstructed image is much worse than for local movement, with a global distortion, as seen in figure~\ref{fig:fly_2}. In this simple isolated case the image could be saved by removing the measurements when the object was moving and reconstructing an image with fewer measurements. The resulting image would not be as good as the image in figure~\ref{fig:fly_2} but it would not contain the noise present in figure~\ref{fig:fly_3}. \\[0.1in]


%Comment luminance change case ?
In the case of luminance change, the effect on the reconstructed image is even worse than for scenes containing movement, which can be seen in figure~\ref{fig:lum_dyn} and by comparing table~\ref{tab:local_dyn}, \ref{tab:fly_dyn} and \ref{tab:lum_dyn}. Because this problem can not be avoided in natural scenes, method to supress it was developed and tested with good result. However as can be seen in figure~\ref{fig:lum_22}, \ref{fig:lum_32} and table~\ref{tab:lum_dyn}, the method will not suppress the effect completely even on a simulation and thus add some global noise in the same form as local movement or signal noise.\\[0.1in]

% SPC
When capturing images using the SPC, the luminance change became a larger problem than anticipated. All images captured in natural lighting had luminance change and it changed at a higher frequency and larger amplitude even in scenes where the intensity seemed stationary. This is of course due to the fact that the intensity change from every mirror in the DMD is summed in the sensor, so even for small changes the sum will change the signal significantly, as seen in figure~\ref{fig:lc_plot}. However as seen in figure~\ref{fig:lc_image}, the moving mean method worked well despite the more complex changes to the signal. Considering that this problem was present for all natural images, this method became essential to produce any good result at all. As stated before, this method is a model of global luminance change in the image, and therefore it is hard to know which side effects this method have on image quality. But as the test showed, the method is essential and was used for all images captured by the SPC and presented and evaluated in this thesis.\\[0.1in]

The moving mean method was mainly constructed because it was known that the SPC would have a long exposure time, but even if the exposure time is reduced to a a few seconds or less, there is some indication that the luminance change will still affect the result. In this thesis, the moving mean window corresponded to 50 milliseconds which indicates that the luminance change is so fast that even reducing exposure time significantly could benefit to this method.\\[0.1in]


Basically all scenes in natural environments contained both dynamics from local movement and luminance change. Local movement often arose from vegetation, objects or clouds moving in the wind but also from turbulence which not move the object but how it is perceived on the DMD. Because of all these dynamic movement existing even in a "static" scene, it was decided not to photograph scenes where large movement occurred i.e. from a car, object or human. Even though such movements could be detected, they could also mistaken for as luminance change.\\[0.1in]

As stated, even "static" scenes will with high probability contain both movement and luminance change which will affect the reconstructed images. Therefor it can be concluded that all reconstructed images in this thesis have to some degree, added global noise from local movement and the moving mean algorithm.


\subsection{Edge response}
When comparing the edge response between the conventional camera against the SPC the results was very clear, the conventional camera outperformed the SPC with one to two pixels in distance. I think that there are multiple factors why the results from the SPC differed so much from the conventional camera, and they are listed below,

\begin{itemize}
\item The largest impact on image quality is probably the reconstruction algorithm which produces "patches", which can be seen in the SPC images in figure~\ref{fig:mtf_target_im}, especially in the contrast of the white background where the light intensity drops. The "patch" artifact from the reconstruction algorithm can affect the sharpness of the image. We can also see from previous tests that even from synthetic data, the BRISQUE score is significantly worse for the reconstructed image than for the original image.

\item The pixel grid setup in the DMD has two problems that could effect the sharpness. The DMD mirrors are aligned in the diamond shape and in the current setup to fix the ratio and index, two mirrors are merged to form one pixel. The reconstruction algorithm will still interpret the measurement as a regular square pixel, which can distort the image.

\item The focus in the DMD is set manually and is possibly not optimal.

\item In this thesis no significant image improvement from post processing such as denoising or sharpening was performed unlike in the conventional camera.

\item As stated before, with the long exposure, vibrations and light intensity change affected the results, which contribute to global noise in the reconstruction. For example, the SPC could detect significant light intensity change from the halogen lamp powered by a DC-unit.

\end{itemize}

Even though the image quality is not in favor to the SPC, I think that the results looks promising and can be improved both by changing to more suitable hardware, such as a DMD with "regular" square mirrors and by using more advanced image denoising algorithms.

\subsection{Subsampling ratio}
The first results from section~\ref{sec:measurements} was the minimum subsampling ratio required to reconstruct a merely recognizable image. It turned out that for the whole image set, the results varied between 2-4\%. The differance in value could depend on several factors such as image complexity, SNR and dynamics in the scene, which everyone contribute to add uncertainty to the equation system.\\[0.1in]

One possible application that take advantage of sampling an image with minimum subsampling ratio is to construct a test image and calibrate the camera for the longer exposure high quality image. The calibration could for example be used to set focus, determine which pixels to include in the image and calculate which subsampling ratio to use given the complexity of the image. The test image is sampled with fewer samples and thus reconstructed faster relative to the high quality images.\\[0.1in]

In the second part of section~\ref{sec:measurements}, a set of images reconstructed with different subsampling ratio was presented. The result is presented for the reader to obtain a more concrete perception of the generated image quality and a supplement to the numerical results given subsampling ratio, but also overall expected image quality.\\[0.1in]

The results show that a stable reconstruction was obtained at 5\% subsampling ratio for all images and that a higher subsampling ratio increased the image quality. With greater subsambling ratio than 15\%, the images start to reach their highest potential where details start to show up and the images gets sharp. Some global noise is present in all images. This noise is probably mainly due to the long exposure time, where dynamics in the scene play a big role. 

\section{Method} %Vad jag tycker om det (personliga tankar)
%In the discussion of method an analysis of replicability, reliability and  validity is held.

The methods used in thesis can be divided into four categories, the SPC hardware, the sampling matrix and reconstruction, post processing and the method used to capture the images. Two of these categories, the hardware setup and the sampling matrix and reconstruction were heavily influenced and implemented by widely accepted methods from articles and experiments. The other two categories, the post-processing and the image capturing, depended more on the hardware limitation and competence achieved from the university.\\[0.1in]

The first method in the chain was feeding the DMD measurement matrices and sampling the signal. Because of the interface to the DMD, which acted as a second monitor to the computer, the method to stream the measurement matrices as a video was thought to be a good method because it was easy to implement. In the early stages of this thesis work a much smaller target resolution of $128 \times 128$ pixels was set and thus significantly fewer measurement matrices needed to be streamed to the DMD while having the same exposure time. With that initial goal in mind, the video player steaming method would have worked well. But when the target resolution was pushed, the video players frame rate had to be pushed to its limits in an application it was not designed to handle. This resulted in a higher probability that the video player would go out of sync and thus ruin the reconstruction and there was no way of knowing if this had happen during the sampling. By the time this issue was discovered there where no time left to implement a new method, although it was much needed.\\[0.1in]

The sampling matrix chosen in this thesis was the permutated sequency ordered Walsh Hadamard measurement matrix. This sampling matrix together with the implemented fast transform in the reconstruction algorithm enabled the huge increase in image resolution. The method of using structurally random matrices is the only feasible method today to enable high resolution and fast reconstruction with low memory usage in the computer. Thus, if implemented optimally both the feeding of measurement matrices to the DMD and reconstruction could be calculated in run time in an agile and memory efficient program.\\[0.1in]

The reconstruction algorithm TVAL3 was used throughout this masters thesis work and was chosen after the literature study where several articles mentioned total variation as a good optimization algorithm for compressive imaging. The algorithm worked as described and according to the developer it is one of the fastest and best reconstruction algorithms that are free to use and available. The only negative criticism of using this algorithm is that it seems to produce a dark tint in the edges of the reconstructed images.\\[0.1in]

In the post-processing quite basic signal and image processing was performed and was intentional designed that way in order to present the result as true as possible. One algorithm that was developed specific for the SPC, was the moving mean algorithm to suppress the impact of lumination change in the sampled signal. The algorithm showed great result and became essential when taking photos of scenes outdoor. Both hardware and software signal denoising was implemented to the architecture, but had to be changed every time the DMD update rate was changed, which happened a couple of times. Finding a new solution every time was a time consuming task and dropped completely in the end when good results was achieved anyway. If there had been more time or a target DMD pattern rate had been set earlier, a good signal denoising implementation could have improved the result.\\[0.1in]

\subsection{Replicability, reliability and validity}
Given the methods in this thesis, I think it would be quite straight forward to replicate this experimental setup and architecture. The setup is quite simple and the software developed is not so heavy, therefore I think the experiments have good replicability.\\[0.1in]

In the case of compressive imaging, the reliability and validity goes hand in hand, if whats being measured is not the correct data, the reconstruction will fail and if the reconstruction succeed, the measurement must be correct. Therefore compressive sensing is very binary, either you get it right or you fail and thus I think my results have both high validity and reliability.  

 
% Reliabilitet är ett begrepp som beskriver mätningens kvalitet: hur väl kan man lita på data som insamlats och hur det används för att dra slutsatser. Om reliabiliteten är hög, så bör samma/liknande resultat kunna uppnås om man gör om studien med samma metod.

%Validitet handlar lite förenklat om huruvida man i en mätning mätt det man tror sig mäta. En studie med hög validitet har alltså en hög grad av trovärdighet.



%\subsection{Work in a Broader context}
%Det ska ingå ett stycke med en diskussion om etiska och samhälleliga aspekter relaterade till arbetet. Detta är viktigt för att påvisa professionell mognad samt för att utbildningsmålen ska kunna uppnås. Om arbetet av någon anledning helt saknar koppling till etiska eller samhälleliga aspekter ska detta explicit anges i stycket Avgränsningar i inledningskapitlet. 

% Jag tror detta är fallet då det är en ny sorts kamera, det finns väl inget morariskt fel att bygga en kamera som är effektivare? och den borde inte få några samhelliga effekter?
